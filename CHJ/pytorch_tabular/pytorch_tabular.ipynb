{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('../../../train_v2_remove.parquet')\n",
    "test_data  = pd.read_parquet('../../../test_v2_remove.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(list(train_data.columns))\n",
    "features.remove(\"CI_HOUR\")\n",
    "features = list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 267, 268, 269]\n",
      "[0, 127, 128, 129, 130, 131, 132, 133, 134, 135, 262, 263, 264, 265, 266, 270, 271, 272, 273]\n"
     ]
    }
   ],
   "source": [
    "categoical_list = []\n",
    "numerical_list = []\n",
    "for idx, column in enumerate(train_data.columns):\n",
    "    if (\"ARI_CO\" in column) or (\"ARI_PO\" in column) or (\"FLAG\" in column) or (\"SHIP_TYPE_CATEGORY\" in column): \n",
    "        categoical_list.append(idx)\n",
    "    else:\n",
    "        numerical_list.append(idx)\n",
    "print(categoical_list)\n",
    "print(numerical_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mixed_classification(train_data):\n",
    "    cat_col_names = []\n",
    "    num_col_names = []\n",
    "    for idx, column in enumerate(train_data.columns):\n",
    "        if (\"ARI_CO\" in column) or (\"ARI_PO\" in column) or (\"FLAG\" in column) or (\"SHIP_TYPE_CATEGORY\" in column): \n",
    "            cat_col_names.append(column)\n",
    "        else:\n",
    "            num_col_names.append(column)\n",
    "    return train_data, cat_col_names, num_col_names\n",
    "\n",
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim>1:\n",
    "        y_true=y_true.ravel()\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred=y_pred.ravel()\n",
    "    val_acc = accuracy_score(y_true, y_pred)\n",
    "    val_f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, cat_col_names, num_col_names = make_mixed_classification(train_data)\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:18:24,704 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n"
     ]
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=['CI_HOUR'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\", # can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "# DEPRECATED\n",
    "# prediction head is defined separately now and head & head_config will be made\n",
    "# mandatory in future releases\n",
    "# model_config = CategoryEmbeddingModelConfig(\n",
    "#     task=\"classification\",\n",
    "#     layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "#     activation=\"LeakyReLU\", # Activation between each layers\n",
    "#     learning_rate = 1e-3\n",
    "# )\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"32-16\", # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "2023-10-22 14:18:24,749 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-10-22 14:18:24,762 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:1050: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:1055: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "2023-10-22 14:18:25,682 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-10-22 14:18:26,285 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Auto select gpus: [0, 1]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-10-22 14:18:28,314 - {pytorch_tabular.tabular_model:573} - INFO - Auto LR Find Started\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Lightning can't create new processes if CUDA is already initialized. Did you manually call `torch.cuda.*` functions, have moved the model to the device, or allocated memory on the GPU any other way? Please remove any such calls, or change the selected strategy. You will have to restart the Python kernel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/HD-AI-Challenge/CHJ/pytorch_tabular/pytorch_tabular.ipynb ì…€ 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4844227d@ssh-remote%2B117.16.94.218/data/HD-AI-Challenge/CHJ/pytorch_tabular/pytorch_tabular.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tabular_model\u001b[39m.\u001b[39;49mfit(train\u001b[39m=\u001b[39;49mtrain, validation\u001b[39m=\u001b[39;49mval)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:694\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[0;34m(self, train, validation, test, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule)\u001b[0m\n\u001b[1;32m    681\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    682\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mProviding test data in `fit` is deprecated and will be removed in next major release.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m Plese use `evaluate` for evaluating on test data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_model(\n\u001b[1;32m    686\u001b[0m     datamodule,\n\u001b[1;32m    687\u001b[0m     loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m     optimizer_params,\n\u001b[1;32m    692\u001b[0m )\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(model, datamodule, callbacks, max_epochs, min_epochs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:574\u001b[0m, in \u001b[0;36mTabularModel.train\u001b[0;34m(self, model, datamodule, callbacks, max_epochs, min_epochs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mauto_lr_find \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mfast_dev_run):\n\u001b[1;32m    573\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mAuto LR Find Started\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 574\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtune(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, train_loader, val_loader)\n\u001b[1;32m    575\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    576\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSuggested LR: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m'\u001b[39m\u001b[39mlr_find\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msuggestion()\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m For plot and detailed analysis, use `find_learning_rate` method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m     \u001b[39m# Parameters in models needs to be initialized again after LR find\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:983\u001b[0m, in \u001b[0;36mTrainer.tune\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, scale_batch_size_kwargs, lr_find_kwargs, method)\u001b[0m\n\u001b[1;32m    980\u001b[0m Trainer\u001b[39m.\u001b[39m_log_api_event(\u001b[39m\"\u001b[39m\u001b[39mtune\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    982\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 983\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49m_tune(\n\u001b[1;32m    984\u001b[0m         model,\n\u001b[1;32m    985\u001b[0m         train_dataloaders,\n\u001b[1;32m    986\u001b[0m         val_dataloaders,\n\u001b[1;32m    987\u001b[0m         dataloaders,\n\u001b[1;32m    988\u001b[0m         datamodule,\n\u001b[1;32m    989\u001b[0m         scale_batch_size_kwargs\u001b[39m=\u001b[39;49mscale_batch_size_kwargs,\n\u001b[1;32m    990\u001b[0m         lr_find_kwargs\u001b[39m=\u001b[39;49mlr_find_kwargs,\n\u001b[1;32m    991\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    992\u001b[0m     )\n\u001b[1;32m    994\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/tuner/tuning.py:101\u001b[0m, in \u001b[0;36mTuner._tune\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, scale_batch_size_kwargs, lr_find_kwargs, method)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m     97\u001b[0m         model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m     lr_find_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mupdate_attr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39mlr_find\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_find(\n\u001b[1;32m    102\u001b[0m         model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mlr_find_kwargs\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mFINISHED\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/tuner/tuning.py:267\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr)\u001b[0m\n\u001b[1;32m    264\u001b[0m lr_finder_callback\u001b[39m.\u001b[39m_early_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m [lr_finder_callback] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcallbacks\n\u001b[0;32m--> 267\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mfit(model, train_dataloaders, val_dataloaders, datamodule)\n\u001b[1;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m [cb \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcallbacks \u001b[39mif\u001b[39;00m cb \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mauto_lr_find \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:36\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mlauncher\u001b[39m.\u001b[39;49mlaunch(trainer_fn, \u001b[39m*\u001b[39;49margs, trainer\u001b[39m=\u001b[39;49mtrainer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:96\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_torchdistx_support()\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_method \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfork\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mforkserver\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     _check_bad_cuda_fork()\n\u001b[1;32m     98\u001b[0m \u001b[39m# The default cluster environment in Lightning chooses a random free port number\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m# This needs to be done in the main process here before starting processes to ensure each rank will connect\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m# through the same port\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy\u001b[39m.\u001b[39mcluster_environment \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_fabric/strategies/launchers/multiprocessing.py:194\u001b[0m, in \u001b[0;36m_check_bad_cuda_fork\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE:\n\u001b[1;32m    193\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m You will have to restart the Python kernel.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 194\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(message)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Lightning can't create new processes if CUDA is already initialized. Did you manually call `torch.cuda.*` functions, have moved the model to the device, or allocated memory on the GPU any other way? Please remove any such calls, or change the selected strategy. You will have to restart the Python kernel."
     ]
    }
   ],
   "source": [
    "tabular_model.fit(train=train, validation=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
