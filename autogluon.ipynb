{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import autogluon\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import bisect\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/train_v2.parquet\")\n",
    "test_df = pd.read_parquet(\"data/test_v2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train_df)\n",
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "label = \"CI_HOUR\"\n",
    "eval_metric = \"mean_absolute_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231010_123004\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=7, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (367440 samples, 183.72 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231010_123004\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   14.79 GB / 498.74 GB (3.0%)\n",
      "Train Data Rows:    367440\n",
      "Train Data Columns: 282\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4090.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 177.84 MB (4.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 253 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['FLAG_Brunei', 'FLAG_Cambodia', 'FLAG_Gambia']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 76): ['ARI_PO_CXL1', 'ARI_PO_DEJ2', 'ARI_PO_DIN2', 'ARI_PO_EFG4', 'ARI_PO_GIW5', 'ARI_PO_GQJ7', 'ARI_PO_IVU2', 'ARI_PO_JEA6', 'ARI_PO_KIU2', 'ARI_PO_LHD1', 'ARI_PO_ONW1', 'ARI_PO_RGT8', 'ARI_PO_XGX5', 'ARI_PO_XZF6', 'ARI_PO_ZME5', 'FLAG_Algeria', 'FLAG_Argentina', 'FLAG_Australia', 'FLAG_Azerbaijan', 'FLAG_Bahrain', 'FLAG_Bermuda', 'FLAG_Brazil', 'FLAG_Bulgaria', 'FLAG_Cameroon', 'FLAG_Chile', 'FLAG_Comoros False', 'FLAG_Cook Islands', 'FLAG_Croatia', 'FLAG_Curacao', 'FLAG_Djibouti', 'FLAG_Dominica', 'FLAG_Egypt', 'FLAG_Equatorial Guinea', 'FLAG_Equatorial Guinea False', 'FLAG_Estonia', 'FLAG_Ethiopia', 'FLAG_Faeroes (Fas)', 'FLAG_Finland', 'FLAG_France', 'FLAG_Gabon', 'FLAG_Georgia', 'FLAG_Ghana', 'FLAG_Guinea-Bissau', 'FLAG_Guyana', 'FLAG_Guyana False', 'FLAG_Honduras', 'FLAG_Irish Republic', 'FLAG_Jordan', 'FLAG_Kiribati', 'FLAG_Kuwait', 'FLAG_Latvia', 'FLAG_Lebanon', 'FLAG_Libya', 'FLAG_Lithuania', 'FLAG_Luxembourg', 'FLAG_Maldives', 'FLAG_Mexico', 'FLAG_Moldova', 'FLAG_Montenegro', 'FLAG_New Zealand', 'FLAG_Norway', 'FLAG_Papua New Guinea', 'FLAG_Peru', 'FLAG_Poland', 'FLAG_Sao Tome & Principe', 'FLAG_Sao Tome & Principe False', 'FLAG_Saudi Arabia', 'FLAG_Seychelles', 'FLAG_Spain (Csr)', 'FLAG_Sri Lanka', 'FLAG_Sweden', 'FLAG_Switzerland', 'FLAG_Syria', 'FLAG_Tanzania', 'FLAG_Togo False', 'FLAG_Ukraine']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 76 | ['ARI_PO_CXL1', 'ARI_PO_DEJ2', 'ARI_PO_DIN2', 'ARI_PO_EFG4', 'ARI_PO_GIW5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  17 | ['AIR_TEMPERATURE', 'BDI_ADJ', 'BREADTH', 'BRENT', 'BUILT', ...]\n",
      "\t\t('int', [])   : 186 | ['ARI_CO_BR', 'ARI_CO_CA', 'ARI_CO_CL', 'ARI_CO_CN', 'ARI_CO_FI', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  17 | ['AIR_TEMPERATURE', 'BDI_ADJ', 'BREADTH', 'BRENT', 'BUILT', ...]\n",
      "\t\t('int', [])       :   9 | ['ATA_LT', 'ID', 'SHIPMANAGER', 'day', 'hour', ...]\n",
      "\t\t('int', ['bool']) : 177 | ['ARI_CO_BR', 'ARI_CO_CA', 'ARI_CO_CL', 'ARI_CO_CN', 'ARI_CO_FI', ...]\n",
      "\t5.3s = Fit runtime\n",
      "\t203 features in original data used to generate 203 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 138.53 MB (3.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 1.074 GB out of 3.946 GB available memory (136.086%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.41 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 1.074 GB out of 3.957 GB available memory (135.725%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.41 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 7 child models (S1F1 - S1F7) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 53.2643\n",
      "[2000]\tvalid_set's l1: 51.3019\n",
      "[3000]\tvalid_set's l1: 49.956\n",
      "[4000]\tvalid_set's l1: 48.933\n",
      "[5000]\tvalid_set's l1: 48.079\n",
      "[6000]\tvalid_set's l1: 47.3321\n",
      "[7000]\tvalid_set's l1: 46.7781\n",
      "[8000]\tvalid_set's l1: 46.2504\n",
      "[9000]\tvalid_set's l1: 45.8885\n",
      "[10000]\tvalid_set's l1: 45.509\n",
      "[1000]\tvalid_set's l1: 52.2301\n",
      "[2000]\tvalid_set's l1: 50.5044\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\BSH\\Programming\\dacon\\HD_challenge\\HD-AI-Challenge\\autogluon.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BSH/Programming/dacon/HD_challenge/HD-AI-Challenge/autogluon.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictor \u001b[39m=\u001b[39m TabularPredictor(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BSH/Programming/dacon/HD_challenge/HD-AI-Challenge/autogluon.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     label\u001b[39m=\u001b[39;49mlabel, problem_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mregression\u001b[39;49m\u001b[39m'\u001b[39;49m, eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BSH/Programming/dacon/HD_challenge/HD-AI-Challenge/autogluon.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\u001b[39m.\u001b[39;49mfit(train_data, presets\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbest_quality\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_gpus\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, num_bag_folds\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m, num_stack_levels\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39mgargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[0;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[0;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[0;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[0;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[0;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[0;32m   1002\u001b[0m )\n\u001b[0;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[0;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m   1013\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39mfit(\n\u001b[0;32m    158\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    159\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39mholdout_frac,\n\u001b[0;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit_trainer,\n\u001b[0;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    167\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    168\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_fit_kwargs,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[0;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[0;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[0;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_multi_levels(\n\u001b[0;32m   2372\u001b[0m     X,\n\u001b[0;32m   2373\u001b[0m     y,\n\u001b[0;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39mhyperparameters,\n\u001b[0;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39mnum_stack_levels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2381\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2382\u001b[0m )\n\u001b[0;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[0;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[0;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[0;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[0;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_core(\n\u001b[0;32m    540\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    541\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    545\u001b[0m     models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m    546\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39mbase_model_names,\n\u001b[0;32m    550\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcore_kwargs,\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[0;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[0;32m    556\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi(\n\u001b[0;32m    674\u001b[0m     X\u001b[39m=\u001b[39mX_init,\n\u001b[0;32m    675\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    679\u001b[0m     models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m    680\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39mstack_name,\n\u001b[0;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39mcompute_score,\n\u001b[0;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39mfit_kwargs,\n\u001b[0;32m    684\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    685\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi_initial(\n\u001b[0;32m   2322\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   2323\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   2324\u001b[0m         models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39mn_repeats_initial,\n\u001b[0;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39mfeature_prune_kwargs,\n\u001b[0;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2330\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[0;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2170\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 2170\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi_fold(\n\u001b[0;32m   2171\u001b[0m         models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m   2172\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2173\u001b[0m         k_fold_start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   2174\u001b[0m         k_fold_end\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m   2175\u001b[0m         n_repeats\u001b[39m=\u001b[39mn_repeats,\n\u001b[0;32m   2176\u001b[0m         n_repeat_start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   2177\u001b[0m         time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2178\u001b[0m         time_split\u001b[39m=\u001b[39mtime_split,\n\u001b[0;32m   2179\u001b[0m         time_ratio\u001b[39m=\u001b[39mtime_ratio,\n\u001b[0;32m   2180\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args,\n\u001b[0;32m   2181\u001b[0m     )\n\u001b[0;32m   2183\u001b[0m multi_fold_time_elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m multi_fold_time_start\n\u001b[0;32m   2184\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[1;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single_full(\n\u001b[0;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[0;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[0;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[0;32m   2049\u001b[0m         )\n\u001b[0;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[1;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_and_save(\n\u001b[0;32m   2052\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   2053\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   2054\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39mstack_name,\n\u001b[0;32m   2059\u001b[0m         level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39mcompute_score,\n\u001b[0;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39mtotal_resources,\n\u001b[0;32m   2062\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs,\n\u001b[0;32m   2063\u001b[0m     )\n\u001b[0;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39mtotal_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[0;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, X_val\u001b[39m=\u001b[39mX_val, y_val\u001b[39m=\u001b[39my_val, total_resources\u001b[39m=\u001b[39mtotal_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py:169\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[1;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     time_limit \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[1;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_fit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, time_limit\u001b[39m=\u001b[39mtime_limit, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:266\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[1;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[39m# Reserve time for final refit model\u001b[39;00m\n\u001b[0;32m    265\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m folds_to_fit \u001b[39m/\u001b[39m (folds_to_fit \u001b[39m+\u001b[39m \u001b[39m1.2\u001b[39m)\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_folds(\n\u001b[0;32m    267\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    268\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    269\u001b[0m     model_base\u001b[39m=\u001b[39mmodel_base,\n\u001b[0;32m    270\u001b[0m     X_pseudo\u001b[39m=\u001b[39mX_pseudo,\n\u001b[0;32m    271\u001b[0m     y_pseudo\u001b[39m=\u001b[39my_pseudo,\n\u001b[0;32m    272\u001b[0m     k_fold\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m    273\u001b[0m     k_fold_start\u001b[39m=\u001b[39mk_fold_start,\n\u001b[0;32m    274\u001b[0m     k_fold_end\u001b[39m=\u001b[39mk_fold_end,\n\u001b[0;32m    275\u001b[0m     n_repeats\u001b[39m=\u001b[39mn_repeats,\n\u001b[0;32m    276\u001b[0m     n_repeat_start\u001b[39m=\u001b[39mn_repeat_start,\n\u001b[0;32m    277\u001b[0m     save_folds\u001b[39m=\u001b[39msave_bag_folds,\n\u001b[0;32m    278\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    279\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m )\n\u001b[0;32m    281\u001b[0m \u001b[39m# FIXME: Cleanup self\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m refit_folds:\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:592\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_folds\u001b[1;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39mfor\u001b[39;00m fold_fit_args \u001b[39min\u001b[39;00m fold_fit_args_list:\n\u001b[0;32m    591\u001b[0m     fold_fitting_strategy\u001b[39m.\u001b[39mschedule_fold_model_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfold_fit_args)\n\u001b[1;32m--> 592\u001b[0m fold_fitting_strategy\u001b[39m.\u001b[39;49mafter_all_folds_scheduled()\n\u001b[0;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m    595\u001b[0m     \u001b[39m# No need to add child times or save child here as this already occurred in the fold_fitting_strategy\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_child(model\u001b[39m=\u001b[39mmodel, add_child_times\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:309\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy.after_all_folds_scheduled\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mafter_all_folds_scheduled\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    308\u001b[0m     \u001b[39mfor\u001b[39;00m job \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjobs:\n\u001b[1;32m--> 309\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_fold_model(job)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:314\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy._fit_fold_model\u001b[1;34m(self, fold_ctx)\u001b[0m\n\u001b[0;32m    312\u001b[0m time_start_fold \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    313\u001b[0m time_limit_fold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_fold_time_limit(fold_ctx)\n\u001b[1;32m--> 314\u001b[0m fold_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_base, time_start_fold, time_limit_fold, fold_ctx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_base_kwargs)\n\u001b[0;32m    315\u001b[0m fold_model, pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_oof(fold_model, fold_ctx)\n\u001b[0;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_bagged_ensemble(fold_model, pred_proba, fold_ctx)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:349\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy._fit\u001b[1;34m(self, model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m     num_cpus \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_cpus, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_resources_per_job\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_cpus\u001b[39m\u001b[39m\"\u001b[39m, math\u001b[39m.\u001b[39minf))\n\u001b[0;32m    348\u001b[0m     num_gpus \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_gpus, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_resources_per_job\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_gpus\u001b[39m\u001b[39m\"\u001b[39m, math\u001b[39m.\u001b[39minf))\n\u001b[1;32m--> 349\u001b[0m fold_model\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX_fold, y\u001b[39m=\u001b[39my_fold, X_val\u001b[39m=\u001b[39mX_val_fold, y_val\u001b[39m=\u001b[39my_val_fold, time_limit\u001b[39m=\u001b[39mtime_limit_fold, num_cpus\u001b[39m=\u001b[39mnum_cpus, num_gpus\u001b[39m=\u001b[39mnum_gpus, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_fold)\n\u001b[0;32m    350\u001b[0m fold_model\u001b[39m.\u001b[39mfit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m time_start_fold\n\u001b[0;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m fold_model\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py:194\u001b[0m, in \u001b[0;36mLGBModel._fit\u001b[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_column in param dict is overridden.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m train_lgb_model(early_stopping_callback_kwargs\u001b[39m=\u001b[39mearly_stopping_callback_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[0;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m LightGBMError:\n\u001b[0;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py:124\u001b[0m, in \u001b[0;36mtrain_lgb_model\u001b[1;34m(early_stopping_callback_kwargs, **train_params)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m booster\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m lgb\u001b[39m.\u001b[39mtrain(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BSH\\.virtualenvs\\HD_challenge-fUY-RInk\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[0;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=label, problem_type='regression', eval_metric=eval_metric,\n",
    ").fit(train_data, presets=\"best_quality\", num_gpus=1, num_bag_folds=7, num_stack_levels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_val  pred_time_val      fit_time  \\\n",
      "0      WeightedEnsemble_L3 -18.241295     318.839151  30091.039016   \n",
      "1     LightGBMLarge_BAG_L2 -18.681279     264.864792   9457.184307   \n",
      "2           XGBoost_BAG_L2 -19.208710     258.366502  26087.445843   \n",
      "3          LightGBM_BAG_L2 -19.577228     236.335318   9211.056249   \n",
      "4    NeuralNetTorch_BAG_L2 -19.960918     209.287764  11834.280827   \n",
      "5          CatBoost_BAG_L2 -20.172213     207.449161  11107.267524   \n",
      "6   RandomForestMSE_BAG_L2 -20.271846     238.172094   9639.945336   \n",
      "7     ExtraTreesMSE_BAG_L2 -20.301756     238.220006   9638.675559   \n",
      "8   NeuralNetFastAI_BAG_L2 -21.416820     210.006616  10224.348350   \n",
      "9        LightGBMXT_BAG_L2 -21.427574     220.666533   9076.245043   \n",
      "10     WeightedEnsemble_L2 -28.325769     100.665054   3465.936976   \n",
      "11         LightGBM_BAG_L1 -29.398178      29.824250    460.296869   \n",
      "12    LightGBMLarge_BAG_L1 -30.106108      70.250242    684.092278   \n",
      "13         CatBoost_BAG_L1 -31.224946       0.584560   2316.019468   \n",
      "14       LightGBMXT_BAG_L1 -44.350867      39.455353    484.338338   \n",
      "15   NeuralNetTorch_BAG_L1 -44.691474       2.387260    861.098649   \n",
      "16          XGBoost_BAG_L1 -50.763981       1.387950     69.523057   \n",
      "17  RandomForestMSE_BAG_L1 -52.388663      30.454598   1231.960412   \n",
      "18    ExtraTreesMSE_BAG_L1 -52.462047      29.562189   1262.367500   \n",
      "19  NeuralNetFastAI_BAG_L1 -58.470385       2.936558   1277.018033   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.006013           5.557248            3       True   \n",
      "1                58.021832         810.469703            2       True   \n",
      "2                51.523542       17440.731239            2       True   \n",
      "3                29.492358         564.341645            2       True   \n",
      "4                 2.444804        3187.566223            2       True   \n",
      "5                 0.606201        2460.552920            2       True   \n",
      "6                31.329134         993.230732            2       True   \n",
      "7                31.377046         991.960955            2       True   \n",
      "8                 3.163656        1577.633746            2       True   \n",
      "9                13.823573         429.530439            2       True   \n",
      "10                0.006002           5.528360            2       True   \n",
      "11               29.824250         460.296869            1       True   \n",
      "12               70.250242         684.092278            1       True   \n",
      "13                0.584560        2316.019468            1       True   \n",
      "14               39.455353         484.338338            1       True   \n",
      "15                2.387260         861.098649            1       True   \n",
      "16                1.387950          69.523057            1       True   \n",
      "17               30.454598        1231.960412            1       True   \n",
      "18               29.562189        1262.367500            1       True   \n",
      "19                2.936558        1277.018033            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          20  \n",
      "1          19  \n",
      "2          17  \n",
      "3          12  \n",
      "4          18  \n",
      "5          14  \n",
      "6          13  \n",
      "7          15  \n",
      "8          16  \n",
      "9          11  \n",
      "10         10  \n",
      "11          2  \n",
      "12          9  \n",
      "13          4  \n",
      "14          1  \n",
      "15          8  \n",
      "16          7  \n",
      "17          3  \n",
      "18          5  \n",
      "19          6  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard(silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ARI_PO_CXL1', 'ARI_PO_DEJ2', 'ARI_PO_DIN2', 'ARI_PO_EFG4', 'ARI_PO_GIW5', 'ARI_PO_GQJ7', 'ARI_PO_IVU2', 'ARI_PO_JEA6', 'ARI_PO_KIU2', 'ARI_PO_LHD1', 'ARI_PO_ONW1', 'ARI_PO_RGT8', 'ARI_PO_XGX5', 'ARI_PO_XZF6', 'ARI_PO_ZME5', 'FLAG_Algeria', 'FLAG_Argentina', 'FLAG_Australia', 'FLAG_Azerbaijan', 'FLAG_Bahrain', 'FLAG_Bermuda', 'FLAG_Brazil', 'FLAG_Brunei', 'FLAG_Bulgaria', 'FLAG_Cambodia', 'FLAG_Cameroon', 'FLAG_Chile', 'FLAG_Comoros False', 'FLAG_Cook Islands', 'FLAG_Croatia', 'FLAG_Curacao', 'FLAG_Djibouti', 'FLAG_Dominica', 'FLAG_Egypt', 'FLAG_Equatorial Guinea', 'FLAG_Equatorial Guinea False', 'FLAG_Estonia', 'FLAG_Ethiopia', 'FLAG_Faeroes (Fas)', 'FLAG_Finland', 'FLAG_France', 'FLAG_Gabon', 'FLAG_Gambia', 'FLAG_Georgia', 'FLAG_Ghana', 'FLAG_Guinea-Bissau', 'FLAG_Guyana', 'FLAG_Guyana False', 'FLAG_Honduras', 'FLAG_Irish Republic', 'FLAG_Jordan', 'FLAG_Kiribati', 'FLAG_Kuwait', 'FLAG_Latvia', 'FLAG_Lebanon', 'FLAG_Libya', 'FLAG_Lithuania', 'FLAG_Luxembourg', 'FLAG_Maldives', 'FLAG_Mexico', 'FLAG_Moldova', 'FLAG_Montenegro', 'FLAG_New Zealand', 'FLAG_Norway', 'FLAG_Papua New Guinea', 'FLAG_Peru', 'FLAG_Poland', 'FLAG_Sao Tome & Principe', 'FLAG_Sao Tome & Principe False', 'FLAG_Saudi Arabia', 'FLAG_Seychelles', 'FLAG_Spain (Csr)', 'FLAG_Sri Lanka', 'FLAG_Sweden', 'FLAG_Switzerland', 'FLAG_Syria', 'FLAG_Tanzania', 'FLAG_Togo False', 'FLAG_Ukraine']\n",
      "Computing feature importance via permutation shuffling for 199 features using 5000 rows with 5 shuffle sets...\n",
      "\t42756.94s\t= Expected runtime (8551.39s per shuffle set)\n",
      "\t29670.79s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WTI</th>\n",
       "      <td>9.335927e+02</td>\n",
       "      <td>8.892089e+00</td>\n",
       "      <td>9.874479e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>951.901645</td>\n",
       "      <td>915.283775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUBAI</th>\n",
       "      <td>8.477199e+02</td>\n",
       "      <td>6.592861e+00</td>\n",
       "      <td>4.389674e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>861.294716</td>\n",
       "      <td>834.145134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRENT</th>\n",
       "      <td>8.380975e+02</td>\n",
       "      <td>8.634389e+00</td>\n",
       "      <td>1.351661e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>855.875866</td>\n",
       "      <td>820.319214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>6.690862e+02</td>\n",
       "      <td>8.742037e+00</td>\n",
       "      <td>3.496268e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>687.086220</td>\n",
       "      <td>651.086268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDI_ADJ</th>\n",
       "      <td>6.536173e+02</td>\n",
       "      <td>9.385299e+00</td>\n",
       "      <td>5.099882e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>672.941755</td>\n",
       "      <td>634.292835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_Israel</th>\n",
       "      <td>1.560934e-07</td>\n",
       "      <td>7.714369e-07</td>\n",
       "      <td>3.371992e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_Philippines</th>\n",
       "      <td>-3.944276e-05</td>\n",
       "      <td>2.432199e-03</td>\n",
       "      <td>5.135946e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>-0.005047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARI_PO_PUF3</th>\n",
       "      <td>-1.957740e-04</td>\n",
       "      <td>4.889346e-03</td>\n",
       "      <td>5.335194e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>-0.010263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_Thailand</th>\n",
       "      <td>-2.649475e-04</td>\n",
       "      <td>2.310960e-03</td>\n",
       "      <td>5.948415e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>-0.005023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_Vanuatu</th>\n",
       "      <td>-4.562075e-04</td>\n",
       "      <td>2.507643e-03</td>\n",
       "      <td>6.475097e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.005619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    importance        stddev       p_value  n    p99_high  \\\n",
       "WTI               9.335927e+02  8.892089e+00  9.874479e-10  5  951.901645   \n",
       "DUBAI             8.477199e+02  6.592861e+00  4.389674e-10  5  861.294716   \n",
       "BRENT             8.380975e+02  8.634389e+00  1.351661e-09  5  855.875866   \n",
       "month             6.690862e+02  8.742037e+00  3.496268e-09  5  687.086220   \n",
       "BDI_ADJ           6.536173e+02  9.385299e+00  5.099882e-09  5  672.941755   \n",
       "...                        ...           ...           ... ..         ...   \n",
       "FLAG_Israel       1.560934e-07  7.714369e-07  3.371992e-01  5    0.000002   \n",
       "FLAG_Philippines -3.944276e-05  2.432199e-03  5.135946e-01  5    0.004968   \n",
       "ARI_PO_PUF3      -1.957740e-04  4.889346e-03  5.335194e-01  5    0.009871   \n",
       "FLAG_Thailand    -2.649475e-04  2.310960e-03  5.948415e-01  5    0.004493   \n",
       "FLAG_Vanuatu     -4.562075e-04  2.507643e-03  6.475097e-01  5    0.004707   \n",
       "\n",
       "                     p99_low  \n",
       "WTI               915.283775  \n",
       "DUBAI             834.145134  \n",
       "BRENT             820.319214  \n",
       "month             651.086268  \n",
       "BDI_ADJ           634.292835  \n",
       "...                      ...  \n",
       "FLAG_Israel        -0.000001  \n",
       "FLAG_Philippines   -0.005047  \n",
       "ARI_PO_PUF3        -0.010263  \n",
       "FLAG_Thailand      -0.005023  \n",
       "FLAG_Vanuatu       -0.005619  \n",
       "\n",
       "[199 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use = predictor.get_model_best()\n",
    "model_pred = predictor.predict(test_data, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           95.837402\n",
       "1          390.109039\n",
       "2            0.018952\n",
       "3            0.149630\n",
       "4           31.008961\n",
       "             ...     \n",
       "244984      93.460342\n",
       "244985     331.323547\n",
       "244986      -0.031149\n",
       "244987      -0.129224\n",
       "244988    1315.939575\n",
       "Name: CI_HOUR, Length: 244989, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submit[\"CI_HOUR\"] = [i if i > 0 else 0.0 for i in model_pred]\n",
    "submit.to_csv(\"./csv/autogluon_v1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
